# Job Matching System â€” Datathon FIAP (Decision)

Resumo
Este repositÃ³rio contÃ©m a soluÃ§Ã£o desenvolvida para o Datathon da FIAP com base no estudo de caso da Decision. O objetivo Ã© automatizar e melhorar o processo de recrutamento usando NLP, embeddings e um Ã­ndice vetorial FAISS para sugerir candidatos relevantes a partir das bases vagas.json, prospects.json e applicants.json.

Contexto do problema
A Decision atua em bodyshop e recrutamento de TI. Hoje o processo exige muito esforÃ§o manual dos hunters e sofre com:
- Falta de padronizaÃ§Ã£o nas entrevistas;
- Dificuldade em avaliar engajamento e fit cultural rapidamente;
- Tempo elevado para encontrar candidatos adequados.

O que foi construÃ­do
1. PrÃ©-processamento dos dados
   - Tratamento e normalizaÃ§Ã£o dos arquivos originais (applicants, prospects, vagas).
   - ExtraÃ§Ã£o de campos relevantes (experiÃªncia, formaÃ§Ã£o, idiomas, skills) e montagem de textos padronizados (CV sintetizado).

2. GeraÃ§Ã£o de embeddings e Ã­ndice FAISS
   - CriaÃ§Ã£o de embeddings para cada candidato e para descriÃ§Ãµes de vaga.
   - IndexaÃ§Ã£o com FAISS usando distÃ¢ncia por similaridade cosseno.
   - Salvamento do index FAISS e do mapeamento candidatoâ†’vetor em arquivos (estes arquivos funcionam como nosso "modelo" em produÃ§Ã£o).

3. MÃ³dulo de recrutador (matching)
   - MÃ³dulo que recebe uma vaga, gera seu embedding e realiza retrieval no Ã­ndice FAISS.
   - Retorna candidatos rankeados pelo score de similaridade.

4. API (FastAPI)
   - Endpoint /predict que recebe texto de descriÃ§Ã£o da vaga e retorna candidatos recomendados (top-K).
   - Usa os arquivos gerados pelo FAISS para responder em produÃ§Ã£o.

5. Web app (Streamlit)
   - Interface para interaÃ§Ã£o human-in-the-loop: enviar descriÃ§Ãµes, ajustar parÃ¢metros, reexecutar buscas e exportar CVs padronizados (experiÃªncia, educaÃ§Ã£o, inglÃªs, curso superior).
   - Permite iteraÃ§Ãµes: basta adicionar/ajustar o texto no chat e solicitar nova seleÃ§Ã£o.

## Boas prÃ¡ticas e notas
- Modelos/Ã­ndices FAISS sÃ£o considerados artefatos de produÃ§Ã£o â€” versionar e salvar hashes.
- Adicione a indexaÃ§Ã£o sempre que novos candidatos forem adicionados.
- Testes unitÃ¡rios (pytest) e cobertura â‰¥ 80% recomendados.

## ğŸ› ï¸ Stack TecnolÃ³gica

- **Linguagem**: Python 3.10
- **Bibliotecas de ML/Processamento**: pandas, numpy, scikit-learn, sentence-transformers
- **Banco Vetorial**: FAISS
- **API**: FastAPI
- **VisualizaÃ§Ã£o**: Streamlit
- **SerializaÃ§Ã£o**: pickle + faiss index
- **Empacotamento**: Docker
- **Testes**: pytest
- **Deploy**: Local (Docker) â€” possÃ­vel extensÃ£o para cloud
- **Monitoramento**: Grafana + Prometheus

## ğŸš€ InÃ­cio RÃ¡pido

### PrÃ©-requisitos
- **Docker** e **Docker Compose** (obrigatÃ³rio)
- **Git** (para clonar o repositÃ³rio)

### Setup Ãšnico
```bash
# 1. Clone o repositÃ³rio
git clone <repository-url>
cd Dataton

# 2. Inicie todo o sistema com um comando
docker-compose up --build -d
```

### ğŸŒ Acessos Web
Aguarde alguns minutos para o build e inicializaÃ§Ã£o, depois acesse:

- **ğŸ¯ Interface Streamlit**: http://localhost:8501 *(Principal - Interface Visual)*
- **ğŸš€ API FastAPI**: http://localhost:8000/docs *(DocumentaÃ§Ã£o da API)*
- **ğŸ“Š Prometheus**: http://localhost:9090 *(MÃ©tricas)*
- **ğŸ“ˆ Grafana**: http://localhost:3000 *(Dashboards - admin/admin123)*

## ğŸ› ï¸ Comandos Docker

```bash
# âœ… Iniciar sistema completo
docker-compose up --build -d

# ğŸ“Š Ver status dos containers
docker-compose ps

# ğŸ“‹ Ver logs gerais
docker-compose logs

# ğŸ” Ver logs de um serviÃ§o especÃ­fico
docker-compose logs streamlit_app
docker-compose logs ml_app

# â¹ï¸ Parar sistema completo
docker-compose down

# ğŸ”„ Rebuild completo (se houver problemas)
docker-compose down
docker-compose up --build -d
```

## ğŸ—‚ï¸ Estrutura do Projeto

```
â”œâ”€â”€ app/                    # API FastAPI
â”‚   â”œâ”€â”€ main.py            # Endpoints da API
â”‚   â””â”€â”€ routes.py          # Rotas organizadas
â”œâ”€â”€ src/                    # CÃ³digo principal do ML
â”‚   â”œâ”€â”€ embedding_manager.py
â”‚   â”œâ”€â”€ recruiter.py       # LÃ³gica de matching
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ streamlit_app.py       # ğŸ¯ Interface web principal
â”œâ”€â”€ requirements.txt       # DependÃªncias Python
â”œâ”€â”€ docker-compose.yml     # ğŸ³ OrquestraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ Dockerfile             # Container da API
â”œâ”€â”€ Dockerfile.streamlit   # Container do Streamlit
â””â”€â”€ prometheus/            # ConfiguraÃ§Ã£o de monitoramento
    â””â”€â”€ prometheus.yml
```

## ğŸ—ï¸ Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   STREAMLIT     â”‚    â”‚   API FASTAPI   â”‚    â”‚   PROMETHEUS    â”‚
â”‚                 â”‚â”€â”€â”€â–¶â”‚                 â”‚â”€â”€â”€â–¶â”‚                 â”‚
â”‚ Interface Visualâ”‚    â”‚ Processa vagas  â”‚    â”‚ Coleta mÃ©tricas â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â–¼                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   FAISS INDEX   â”‚    â”‚    GRAFANA      â”‚
                       â”‚                 â”‚    â”‚                 â”‚
                       â”‚ Busca candidatosâ”‚    â”‚ Visualiza dados â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ Como Funciona o Matching

1. **Entrada**: DescriÃ§Ã£o da vaga (texto)
2. **Processamento**: 
   - Classifica Ã¡rea de trabalho (desenvolvimento, dados, design...)
   - Extrai nÃ­vel de experiÃªncia (junior, pleno, senior...)
   - Gera embedding (vetor de 384 dimensÃµes)
3. **Busca**: FAISS encontra candidatos similares
4. **Resultado**: Lista de candidatos com scores de compatibilidade

## ğŸ§ª Testando o Sistema

### 1ï¸âƒ£ Verificar Containers
```bash
docker-compose ps
```
*Deve mostrar 4 serviÃ§os rodando: ml_app, streamlit_app, prometheus, grafana*

### 2ï¸âƒ£ Testar Interface Principal
- Acesse: http://localhost:8501
- Use a interface para fazer matching de candidatos

### 3ï¸âƒ£ Testar API
- DocumentaÃ§Ã£o: http://localhost:8000/docs
- Teste o endpoint `/predict`:
```json
{
  "job_description": "Desenvolvedor Python sÃªnior com experiÃªncia em machine learning",
  "top_n": 5,
  "search_k": 50
}
```
- Endpoint `/metrics` para mÃ©tricas Prometheus
- Endpoint `/health` para status da aplicaÃ§Ã£o

### 4ï¸âƒ£ Verificar Monitoramento
**Prometheus** (http://localhost:9090):
- VÃ¡ em **Status â†’ Targets**
- Verifique se `ml_app:8000` estÃ¡ **UP**
- Teste query: `job_matching_requests_total`

**Grafana** (http://localhost:3000):
- Login: **admin / admin123**
- Data Source jÃ¡ configurado: `http://prometheus:9090`
- Dashboard prÃ©-configurado disponÃ­vel

## ğŸ“Š MÃ©tricas e Monitoramento

### MÃ©tricas Coletadas Automaticamente:
- **Performance**: Taxa de requisiÃ§Ãµes, latÃªncia, tempo de busca FAISS
- **NegÃ³cio**: Candidatos encontrados, scores de matching, Ã¡reas mais buscadas
- **Sistema**: SaÃºde dos componentes, uso de memÃ³ria, status da aplicaÃ§Ã£o

### Queries Ãšteis para Grafana:
```prometheus
# Total de requisiÃ§Ãµes
job_matching_requests_total

# Taxa de requisiÃ§Ãµes por minuto
rate(job_matching_requests_total[1m])

# Candidatos encontrados
job_matching_candidates_found_sum

# Buscas por Ã¡rea
job_matching_searches_by_area_total

# DuraÃ§Ã£o mÃ©dia das requisiÃ§Ãµes
job_matching_request_duration_seconds_sum / job_matching_request_duration_seconds_count
```

## ğŸ”§ Troubleshooting

### Problema: Containers nÃ£o iniciam
```bash
# Ver logs detalhados
docker-compose logs

# Limpar e tentar novamente
docker-compose down
docker-compose up --build -d
```

### Problema: ImportError com huggingface_hub
Se aparecer erro `cannot import name 'cached_download' from 'huggingface_hub'`:
- âœ… **JÃ¡ corrigido**: O projeto usa versÃµes compatÃ­veis fixas
- `sentence-transformers==3.1.1` 
- `huggingface-hub==0.19.4`

### Problema: Porta ocupada
```bash
# Verificar portas em uso no Windows
netstat -ano | findstr :8000
netstat -ano | findstr :8501

# Parar outros serviÃ§os ou alterar portas no docker-compose.yml
```

### Problema: Build muito lento
- O primeiro build pode levar varios minutos (download de modelos ML)
- Builds subsequentes sÃ£o mais rÃ¡pidos (cache do Docker)
- Use `docker-compose up --build -d` para rebuild otimizado

## ğŸ“‹ Logs e Monitoramento

```bash
# Ver status geral
docker-compose ps

# Logs em tempo real
docker-compose logs -f

# Logs de um serviÃ§o especÃ­fico
docker-compose logs -f streamlit_app
docker-compose logs -f ml_app
```

## ğŸ¤ Contributing

Contributions are welcome! Please open an issue or submit a pull request for any improvements or bug fixes.

## ğŸ“„ License

This project is licensed under the MIT License.